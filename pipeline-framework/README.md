# Pipeline Framework

åŸºäº Spring Boot å’Œ Project Reactor çš„å“åº”å¼ ETL æ•°æ®å¤„ç†æ¡†æ¶ã€‚

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- âœ… **æ’ä»¶åŒ– Connector æœºåˆ¶** - Connector ä¸ä¾èµ– Reactorï¼Œå¯ç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•
- âœ… **å¼ºç±»å‹æ³›å‹çº¦æŸ** - å¤šå±‚æ¬¡æ³›å‹å‚æ•°ï¼Œæä¾›ç±»å‹å®‰å…¨ä¿éšœ
- âœ… **ä¸°å¯Œçš„è®¾è®¡æ¨¡å¼** - å·¥å‚ã€é€‚é…å™¨ã€æ¨¡æ¿æ–¹æ³•ã€ç­–ç•¥ã€å»ºé€ è€…ç­‰æ¨¡å¼åº”ç”¨
- âœ… **çµæ´»çš„æ¶æ„åˆ†å±‚** - Connector å±‚ã€Adapter å±‚ã€Component å±‚æ¸…æ™°åˆ†ç¦»
- âœ… **å“åº”å¼æ•°æ®æµ** - åŸºäº Project Reactorï¼Œæ”¯æŒèƒŒå‹ã€å¼‚æ­¥ã€éé˜»å¡
- âœ… **å¤šç§ä»»åŠ¡ç±»å‹** - STREAMINGï¼ˆæµå¼ï¼‰ã€BATCHï¼ˆæ‰¹å¤„ç†ï¼‰ã€SQL_BATCHï¼ˆSQL æ‰¹å¤„ç†ï¼‰

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### åˆ†å±‚è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Application Layer                      â”‚
â”‚              (Job Definition & Execution)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Component Layer                         â”‚
â”‚         (DataSource, Operator, DataSink)                 â”‚
â”‚              [ä¾èµ– Reactor]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Adapter Layer                          â”‚
â”‚    (Readerâ†’Source, Writerâ†’Sink é€‚é…)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Connector Layer                         â”‚
â”‚     (ConnectorReader, ConnectorWriter)                   â”‚
â”‚              [ä¸ä¾èµ– Reactor]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                External Systems
          (JDBC, Kafka, Redis, File...)
```

### å…³é”®è®¾è®¡æ¨¡å¼

| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | ç±»/æ¥å£ |
|------|---------|---------|
| ğŸ­ å·¥å‚æ¨¡å¼ | Connector åˆ›å»º | `ConnectorFactory`, `ConnectorFactoryRegistry` |
| ğŸ”Œ é€‚é…å™¨æ¨¡å¼ | Connector â†’ Component | `DefaultReaderToSourceAdapter`, `DefaultWriterToSinkAdapter` |
| ğŸ“‹ æ¨¡æ¿æ–¹æ³•æ¨¡å¼ | é€šç”¨æµç¨‹éª¨æ¶ | `AbstractJdbcConnector`, `AbstractConnectorAdapter` |
| ğŸ¯ ç­–ç•¥æ¨¡å¼ | å¯æ›¿æ¢çš„ç®—æ³• | `ConnectorType` æšä¸¾ + å¤šç§ Connector å®ç° |
| ğŸ”§ å»ºé€ è€…æ¨¡å¼ | å¤æ‚å¯¹è±¡æ„å»º | `ConnectorMetadata.Builder`, `ComponentMetadata.Builder` |
| ğŸ“ æ³¨å†Œè¡¨æ¨¡å¼ | åŠ¨æ€æ³¨å†Œ | `ConnectorFactoryRegistry` |

---

## ğŸ“¦ æ¨¡å—ç»“æ„

```
pipeline-framework/
â”œâ”€â”€ pipeline-api/              # æ ¸å¿ƒæ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ connector/            # Connector æ¥å£
â”‚   â”‚   â”œâ”€â”€ adapter/         # é€‚é…å™¨æ¥å£
â”‚   â”‚   â””â”€â”€ factory/         # å·¥å‚æ¥å£
â”‚   â”œâ”€â”€ component/            # Component åŸºç¡€æ¥å£
â”‚   â”œâ”€â”€ source/               # DataSource æ¥å£
â”‚   â”œâ”€â”€ sink/                 # DataSink æ¥å£
â”‚   â””â”€â”€ operator/             # Operator æ¥å£
â”‚
â”œâ”€â”€ pipeline-core/             # æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ connector/            # Adapter å®ç°
â”‚   â”œâ”€â”€ builder/              # Pipeline æ„å»ºå™¨
â”‚   â””â”€â”€ runtime/              # è¿è¡Œæ—¶
â”‚
â”œâ”€â”€ pipeline-connectors/       # Connector å®ç°
â”‚   â”œâ”€â”€ jdbc/                 # JDBC Connector
â”‚   â”œâ”€â”€ kafka/                # Kafka Connector
â”‚   â””â”€â”€ console/              # Console Connector
â”‚
â”œâ”€â”€ pipeline-operators/        # Operator å®ç°
â”œâ”€â”€ pipeline-executor/         # æ‰§è¡Œå™¨
â”œâ”€â”€ pipeline-scheduler/        # è°ƒåº¦å™¨
â”œâ”€â”€ pipeline-state/            # çŠ¶æ€ç®¡ç†
â”œâ”€â”€ pipeline-checkpoint/       # æ£€æŸ¥ç‚¹
â”œâ”€â”€ pipeline-metrics/          # ç›‘æ§æŒ‡æ ‡
â””â”€â”€ pipeline-starter/          # Spring Boot å¯åŠ¨å™¨
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»º Connectorï¼ˆä¸ä¾èµ– Reactorï¼‰

```java
// é…ç½®
JdbcConnectorConfig config = new JdbcConnectorConfig();
config.setUrl("jdbc:mysql://localhost:3306/test");
config.setUsername("root");
config.setPassword("password");
config.setQuerySql("SELECT * FROM users");

// åˆ›å»º Reader
JdbcConnectorReader reader = new JdbcConnectorReader(config);
reader.open();

// è¯»å–æ•°æ®
List<Map<String, Object>> batch = reader.readBatch(1000);
System.out.println("Read: " + batch.size() + " records");

reader.close();
```

### 2. ä½¿ç”¨å·¥å‚æ¨¡å¼

```java
// æ³¨å†Œå·¥å‚
ConnectorFactoryRegistry registry = ConnectorFactoryRegistry.getInstance();
registry.register(ConnectorType.JDBC, new JdbcConnectorFactory());

// åˆ›å»º Connector
ConnectorReader<Map<String, Object>, JdbcConnectorConfig> reader = 
    registry.createReader(ConnectorType.JDBC, config);
```

### 3. è½¬æ¢ä¸º Componentï¼ˆé›†æˆ Reactorï¼‰

```java
// åˆ›å»ºé€‚é…å™¨
DefaultReaderToSourceAdapter<Map<String, Object>, JdbcConnectorConfig> adapter =
    new DefaultReaderToSourceAdapter<>(reader, 1000);

// è·å– DataSource
DataSource<Map<String, Object>> source = adapter.adapt(reader);

// ä½¿ç”¨å“åº”å¼æµ
Flux<Map<String, Object>> stream = source.read();
stream.subscribe(data -> System.out.println(data));
```

### 4. å®Œæ•´ ETL æµç¨‹

```java
// æºå’Œç›®æ ‡
ConnectorReader reader = registry.createReader(ConnectorType.JDBC, sourceConfig);
ConnectorWriter writer = registry.createWriter(ConnectorType.JDBC, sinkConfig);

// é€‚é…ä¸º Component
DataSource source = new DefaultReaderToSourceAdapter(reader, 1000).adapt(reader);
DataSink sink = new DefaultWriterToSinkAdapter(writer, 1000).adapt(writer);

// æ‰§è¡Œ ETL
source.read()
    .map(data -> {
        // æ•°æ®è½¬æ¢
        data.put("migrated_at", System.currentTimeMillis());
        return data;
    })
    .filter(data -> data.get("email") != null) // è¿‡æ»¤
    .transform(dataStream -> sink.write(dataStream))
    .block();
```

---

## ğŸ’¡ æ ¸å¿ƒæ¥å£

### Connector å±‚ï¼ˆä¸ä¾èµ– Reactorï¼‰

```java
// é¡¶å±‚æ¥å£
public interface Connector<C extends ConnectorConfig> {
    String getName();
    ConnectorType getType();
    C getConfig();
    ConnectorMetadata getMetadata();
}

// Reader æ¥å£
public interface ConnectorReader<T, C extends ConnectorConfig> extends Connector<C> {
    void open() throws Exception;
    List<T> readBatch(int batchSize) throws Exception;
    boolean hasNext();
    void close() throws Exception;
    
    // å¯é€‰èƒ½åŠ›
    Object getCheckpoint();
    void seekToCheckpoint(Object checkpoint) throws Exception;
    boolean supportsCheckpoint();
    double getProgress();
    long getReadCount();
}

// Writer æ¥å£
public interface ConnectorWriter<T, C extends ConnectorConfig> extends Connector<C> {
    void open() throws Exception;
    void write(T record) throws Exception;
    void writeBatch(List<T> records) throws Exception;
    void flush() throws Exception;
    void close() throws Exception;
    
    // äº‹åŠ¡èƒ½åŠ›
    boolean supportsTransaction();
    void beginTransaction() throws Exception;
    void commit() throws Exception;
    void rollback() throws Exception;
}
```

### Component å±‚ï¼ˆä¾èµ– Reactorï¼‰

```java
// Component åŸºç¡€æ¥å£
public interface Component<C> {
    String getName();
    ComponentType getComponentType();
    C getConfig();
}

// DataSource æ¥å£
public interface DataSource<OUT> extends Component<SourceConfig>, LifecycleAware {
    Flux<OUT> read();
    SourceType getType();
}

// DataSink æ¥å£
public interface DataSink<IN> extends Component<SinkConfig>, LifecycleAware {
    Mono<Void> write(Flux<IN> data);
    Mono<Void> flush();
}

// Operator æ¥å£
public interface Operator<IN, OUT> extends StreamingComponent<IN, OUT, OperatorConfig> {
    Flux<OUT> apply(Flux<IN> input);
    OperatorType getType();
}
```

---

## ğŸ“š å¼€å‘æŒ‡å—

### åˆ›å»ºè‡ªå®šä¹‰ Connector

1. **å®šä¹‰é…ç½®ç±»**

```java
public class MyConnectorConfig extends ConnectorConfig {
    private String endpoint;
    
    @Override
    public void validate() {
        if (endpoint == null) {
            throw new IllegalArgumentException("Endpoint required");
        }
    }
}
```

2. **å®ç° Reader**

```java
public class MyConnectorReader extends AbstractMyConnector<MyDataType>
    implements ReadableConnector<MyDataType, MyConnectorConfig> {
    
    @Override
    protected void doOpen() throws Exception {
        // åˆå§‹åŒ–è¿æ¥
    }
    
    @Override
    public List<MyDataType> readBatch(int batchSize) throws Exception {
        // è¯»å–æ•°æ®
    }
    
    @Override
    protected void doClose() throws Exception {
        // æ¸…ç†èµ„æº
    }
}
```

3. **å®ç°å·¥å‚**

```java
public class MyConnectorFactory 
    implements ConnectorFactory<MyDataType, MyConnectorConfig> {
    
    @Override
    public ConnectorReader<MyDataType, MyConnectorConfig> createReader(
        MyConnectorConfig config) throws ConnectorException {
        return new MyConnectorReader(config);
    }
    
    @Override
    public ConnectorType getSupportedType() {
        return ConnectorType.CUSTOM;
    }
}
```

4. **æ³¨å†Œä½¿ç”¨**

```java
ConnectorFactoryRegistry.getInstance()
    .register(ConnectorType.CUSTOM, new MyConnectorFactory());
```

è¯¦ç»†å¼€å‘æŒ‡å—è¯·å‚è€ƒï¼š[CONNECTOR_DEVELOPMENT_GUIDE.md](CONNECTOR_DEVELOPMENT_GUIDE.md)

---

## ğŸ“– æ–‡æ¡£

- [æ¶æ„è®¾è®¡æ–‡æ¡£](ARCHITECTURE_DESIGN.md) - è¯¦ç»†çš„æ¶æ„è¯´æ˜å’Œè®¾è®¡æ¨¡å¼åº”ç”¨
- [Connector å¼€å‘æŒ‡å—](CONNECTOR_DEVELOPMENT_GUIDE.md) - å¦‚ä½•å¼€å‘è‡ªå®šä¹‰ Connector
- [é¡¹ç›®ç»“æ„è¯´æ˜](STRUCTURE.md) - æ¨¡å—ç»“æ„å’Œç›®å½•è¯´æ˜
- [å¿«é€Ÿå¼€å§‹](QUICK_START.md) - ä»é›¶å¼€å§‹æ„å»ºç¬¬ä¸€ä¸ª Pipeline

---

## ğŸ¨ è®¾è®¡äº®ç‚¹

### 1. èŒè´£åˆ†ç¦»

- **Connector å±‚**ï¼šä¸“æ³¨ I/O æ“ä½œï¼Œä¸ä¾èµ– Reactorï¼Œæ˜“äºæµ‹è¯•
- **Adapter å±‚**ï¼šè´Ÿè´£è½¬æ¢ï¼Œå°† Connector é€‚é…ä¸º Component
- **Component å±‚**ï¼šå“åº”å¼æ•°æ®å¤„ç†ï¼Œå……åˆ†åˆ©ç”¨ Reactor çš„èƒ½åŠ›

### 2. æ³›å‹çº¦æŸ

```java
// å¤šå±‚æ¬¡æ³›å‹å‚æ•°
Connector<C extends ConnectorConfig>
ConnectorReader<T, C extends ConnectorConfig>
StreamingComponent<IN, OUT, C>
ConnectorAdapter<CONN extends Connector<C>, COMP extends Component<?>, C extends ConnectorConfig>
```

### 3. è®¾è®¡æ¨¡å¼ç»„åˆ

- å·¥å‚æ¨¡å¼ + æ³¨å†Œè¡¨æ¨¡å¼ = åŠ¨æ€æ‰©å±•
- é€‚é…å™¨æ¨¡å¼ + æ¨¡æ¿æ–¹æ³•æ¨¡å¼ = çµæ´»è½¬æ¢
- ç­–ç•¥æ¨¡å¼ + æ³›å‹çº¦æŸ = ç±»å‹å®‰å…¨

### 4. æ˜“äºæ‰©å±•

- æ–°å¢ Connectorï¼šå®ç°æ¥å£ + æ³¨å†Œå·¥å‚
- æ–°å¢ Operatorï¼šç»§æ‰¿ StreamingComponent
- æ–°å¢ Job ç±»å‹ï¼šæ‰©å±• JobType æšä¸¾

---

## ğŸ”§ æŠ€æœ¯æ ˆ

- **Spring Boot 3.x** - åº”ç”¨æ¡†æ¶
- **Project Reactor** - å“åº”å¼ç¼–ç¨‹
- **Java 17+** - ç¼–ç¨‹è¯­è¨€
- **Maven** - æ„å»ºå·¥å…·
- **SLF4J + Logback** - æ—¥å¿—
- **JUnit 5** - å•å…ƒæµ‹è¯•

---

## ğŸ“Š ç¤ºä¾‹åœºæ™¯

### åœºæ™¯ 1ï¼šMySQL åˆ° MySQL çš„æ•°æ®è¿ç§»

```java
// æºæ•°æ®åº“
JdbcConnectorConfig source = new JdbcConnectorConfig();
source.setUrl("jdbc:mysql://source:3306/db");
source.setQuerySql("SELECT * FROM users WHERE active = 1");

// ç›®æ ‡æ•°æ®åº“
JdbcConnectorConfig sink = new JdbcConnectorConfig();
sink.setUrl("jdbc:mysql://target:3306/db");
sink.setTableName("users_backup");

// æ‰§è¡Œè¿ç§»
registry.createReader(ConnectorType.JDBC, source)
    .adapt()
    .read()
    .transform(data -> transform(data))
    .writeTo(registry.createWriter(ConnectorType.JDBC, sink));
```

### åœºæ™¯ 2ï¼šå®æ—¶æ—¥å¿—å¤„ç†

```java
// Kafka è¯»å–æ—¥å¿—
kafkaSource.read()
    .filter(log -> log.getLevel() == Level.ERROR)
    .map(log -> enrichLog(log))
    .writeTo(elasticsearchSink);
```

### åœºæ™¯ 3ï¼šæ‰¹é‡æ•°æ®èšåˆ

```java
// è¯»å–è®¢å•æ•°æ®
jdbcSource.read()
    .buffer(Duration.ofSeconds(10))
    .map(orders -> aggregateOrders(orders))
    .writeTo(redisSink);
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

å¼€å‘æŒ‡å—ï¼š
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/my-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -am 'Add my feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/my-feature`
5. æäº¤ Pull Request

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ‘¥ å›¢é˜Ÿ

Pipeline Framework Team

---

**ç‰ˆæœ¬**ï¼š1.0.0  
**æœ€åæ›´æ–°**ï¼š2025-11-10

ğŸš€ å¿«é€Ÿå¼€å§‹ï¼Œç«‹å³ä½“éªŒå¼ºå¤§çš„ ETL æ¡†æ¶ï¼
