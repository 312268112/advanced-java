# Pipeline Framework å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆé‡æ„ç‰ˆï¼‰

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ å¿«é€Ÿäº†è§£å’Œä½¿ç”¨é‡æ„åçš„Pipeline Frameworkã€‚

## ğŸ“¦ å‰ç½®æ¡ä»¶

- JDK 17+
- Maven 3.9+
- MySQL 8.0+ï¼ˆç”¨äºSQLæ‰¹é‡ä»»åŠ¡ï¼‰

## ğŸ”§ å®‰è£…

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd pipeline-framework
```

### 2. ç¼–è¯‘å®‰è£…

```bash
mvn clean install -DskipTests
```

### 3. é…ç½®æ•°æ®åº“

ç¼–è¾‘ `pipeline-starter/src/main/resources/application-dev.yml`:

```yaml
spring:
  datasource:
    url: jdbc:mysql://localhost:3306/pipeline_framework
    username: root
    password: your_password
```

### 4. å¯åŠ¨åº”ç”¨

```bash
cd pipeline-starter
mvn spring-boot:run
```

## ğŸ’¡ æ ¸å¿ƒç‰¹æ€§

### âœ¨ ä¸‰ç§ä»»åŠ¡ç±»å‹

```java
// 1. æµå¼ä»»åŠ¡ - æŒç»­è¿è¡Œï¼ˆå¦‚Kafkaæ¶ˆè´¹ï¼‰
JobType.STREAMING

// 2. æ‰¹å¤„ç†ä»»åŠ¡ - ä¸€æ¬¡æ€§æ‰§è¡Œï¼ˆå¦‚æ–‡ä»¶å¯¼å…¥ï¼‰
JobType.BATCH

// 3. SQLæ‰¹é‡ä»»åŠ¡ - å¤§SQLå¤šè¡¨æ•´åˆï¼ˆæ–°å¢ï¼‰
JobType.SQL_BATCH
```

### âš™ï¸ è‡ªåŠ¨é…ç½®

æ— éœ€æ‰‹åŠ¨é…ç½®Beanï¼Œæ‰€æœ‰ç»„ä»¶è‡ªåŠ¨è£…é…ï¼

```yaml
pipeline:
  framework:
    enabled: true  # é»˜è®¤å¯ç”¨
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šç®€å•çš„SQLæ‰¹é‡ä»»åŠ¡

```java
@Service
public class MyService {
    
    @Autowired
    private DataSource dataSource;
    
    @Autowired
    private BatchJobExecutor executor;
    
    public void runSqlBatchJob() {
        // 1. åˆ›å»ºSourceï¼ˆä»å“ªé‡Œè¯»æ•°æ®ï¼‰
        SqlBatchSourceConfig sourceConfig = SqlBatchSourceConfig.builder()
            .componentId("my-source")
            .sql("SELECT * FROM source_table WHERE id > 1000")
            .fetchSize(500)
            .build();
        
        SqlBatchSource source = new SqlBatchSource(sourceConfig, dataSource);
        
        // 2. åˆ›å»ºSinkï¼ˆå†™åˆ°å“ªé‡Œå»ï¼‰
        SqlBatchSinkConfig sinkConfig = SqlBatchSinkConfig.builder()
            .componentId("my-sink")
            .tableName("target_table")
            .batchSize(1000)
            .build();
        
        SqlBatchSink sink = new SqlBatchSink(sinkConfig, dataSource);
        
        // 3. æ‰§è¡Œä»»åŠ¡
        executor.execute(createJob(source, sink))
            .subscribe(result -> {
                System.out.println("å¤„ç†äº† " + 
                    result.getMetrics().getRecordsProcessed() + " æ¡è®°å½•");
            });
    }
}
```

### ç¤ºä¾‹2ï¼šå¤šè¡¨å…³è”æŸ¥è¯¢

```java
public void joinMultipleTables() {
    SqlBatchSourceConfig sourceConfig = SqlBatchSourceConfig.builder()
        .componentId("join-source")
        .sql("""
            SELECT 
                o.order_id,
                c.customer_name,
                SUM(oi.quantity * oi.price) as total
            FROM orders o
            JOIN customers c ON o.customer_id = c.id
            JOIN order_items oi ON o.order_id = oi.order_id
            GROUP BY o.order_id, c.customer_name
        """)
        .fetchSize(1000)
        .build();
    
    // ... åˆ›å»ºsinkå¹¶æ‰§è¡Œ
}
```

### ç¤ºä¾‹3ï¼šå¸¦å‚æ•°çš„æŸ¥è¯¢

```java
public void queryWithParameters(LocalDate startDate, LocalDate endDate) {
    SqlBatchSourceConfig sourceConfig = SqlBatchSourceConfig.builder()
        .componentId("param-source")
        .sql("SELECT * FROM orders WHERE order_date BETWEEN ? AND ?")
        .parameters(List.of(startDate, endDate))
        .fetchSize(500)
        .build();
    
    // ... åˆ›å»ºsinkå¹¶æ‰§è¡Œ
}
```

## âš™ï¸ é…ç½®è¯´æ˜

### application.yml å®Œæ•´é…ç½®

```yaml
pipeline:
  framework:
    enabled: true
    
    # æ‰§è¡Œå™¨é…ç½®
    executor:
      core-pool-size: 10        # æ ¸å¿ƒçº¿ç¨‹æ•°
      max-pool-size: 50         # æœ€å¤§çº¿ç¨‹æ•°
      queue-capacity: 500       # é˜Ÿåˆ—å®¹é‡
      
    # SQLæ‰¹é‡ä»»åŠ¡é…ç½®
    sql-batch:
      enabled: true
      batch-size: 1000          # æ‰¹æ¬¡å¤§å°
      fetch-size: 500           # æ¯æ¬¡è·å–è¡Œæ•°
      query-timeout-seconds: 300 # æŸ¥è¯¢è¶…æ—¶
      parallel-query: true      # æ˜¯å¦å¹¶è¡Œ
      parallelism: 4            # å¹¶è¡Œåº¦
      
    # æ£€æŸ¥ç‚¹é…ç½®ï¼ˆå®¹é”™ï¼‰
    checkpoint:
      enabled: true
      interval-seconds: 60      # æ£€æŸ¥ç‚¹é—´éš”
      storage-path: ./checkpoints
      
    # ç›‘æ§æŒ‡æ ‡
    metrics:
      enabled: true
      report-interval-seconds: 30
```

## ğŸ¯ å¸¸è§åœºæ™¯

### åœºæ™¯1ï¼šæ•°æ®ETL

```java
// ä»MySQLè¯»å– -> å¤„ç† -> å†™å…¥MySQL
public void etlJob() {
    // è¯»å–æºæ•°æ®
    SqlBatchSource source = createSource("SELECT * FROM source_table");
    
    // å†™å…¥ç›®æ ‡è¡¨
    SqlBatchSink sink = createSink("target_table");
    
    // æ‰§è¡Œ
    executor.execute(createJob(source, sink)).subscribe();
}
```

### åœºæ™¯2ï¼šæŠ¥è¡¨ç”Ÿæˆ

```java
// å¤æ‚SQLèšåˆ -> ç”ŸæˆæŠ¥è¡¨
public void generateReport() {
    SqlBatchSource source = createSource("""
        SELECT 
            DATE(order_date) as date,
            COUNT(*) as order_count,
            SUM(amount) as total_amount
        FROM orders
        GROUP BY DATE(order_date)
    """);
    
    SqlBatchSink sink = createSink("daily_report");
    
    executor.execute(createJob(source, sink)).subscribe();
}
```

### åœºæ™¯3ï¼šæ•°æ®åŒæ­¥

```java
// å®šæ—¶åŒæ­¥å¢é‡æ•°æ®
@Scheduled(cron = "0 0 * * * ?")  // æ¯å°æ—¶æ‰§è¡Œ
public void syncData() {
    SqlBatchSource source = createSource("""
        SELECT * FROM transactions 
        WHERE updated_at > ?
    """, lastSyncTime);
    
    SqlBatchSink sink = createSink("transactions_backup");
    
    executor.execute(createJob(source, sink)).subscribe();
}
```

## ğŸ“Š æ€§èƒ½è°ƒä¼˜

### å°æ•°æ®é‡ï¼ˆ< 10ä¸‡æ¡ï¼‰

```yaml
pipeline.framework.sql-batch:
  batch-size: 500
  fetch-size: 200
  parallel-query: false
```

### ä¸­ç­‰æ•°æ®é‡ï¼ˆ10ä¸‡ - 100ä¸‡æ¡ï¼‰

```yaml
pipeline.framework.sql-batch:
  batch-size: 1000
  fetch-size: 500
  parallel-query: true
  parallelism: 4
```

### å¤§æ•°æ®é‡ï¼ˆ> 100ä¸‡æ¡ï¼‰

```yaml
pipeline.framework.sql-batch:
  batch-size: 2000
  fetch-size: 1000
  parallel-query: true
  parallelism: 8
  max-memory-mb: 1024
```

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€

```java
executor.getJobResult(jobId)
    .subscribe(result -> {
        System.out.println("çŠ¶æ€: " + result.getStatus());
        System.out.println("å·²å¤„ç†: " + result.getMetrics().getRecordsProcessed());
        System.out.println("å¤±è´¥: " + result.getMetrics().getRecordsFailed());
    });
```

### è®¿é—®ç›‘æ§ç«¯ç‚¹

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8080/actuator/health

# PrometheusæŒ‡æ ‡
curl http://localhost:8080/actuator/prometheus

# æ‰€æœ‰ç«¯ç‚¹
curl http://localhost:8080/actuator
```

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†å¤§ç»“æœé›†ï¼Ÿ

**A:** è®¾ç½®åˆé€‚çš„fetch sizeï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼š

```java
sourceConfig.setFetchSize(500);  // æ¯æ¬¡åªè·å–500è¡Œ
```

### Q2: å¦‚ä½•å®ç°äº‹åŠ¡å›æ»šï¼Ÿ

**A:** SqlBatchSinkè‡ªåŠ¨æ”¯æŒäº‹åŠ¡ï¼Œæ‰¹æ¬¡å¤±è´¥ä¼šè‡ªåŠ¨å›æ»šï¼š

```java
sinkConfig.setBatchSize(1000);  // 1000æ¡ä¸ºä¸€ä¸ªäº‹åŠ¡
```

### Q3: å¦‚ä½•æé«˜æ€§èƒ½ï¼Ÿ

**A:** å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢ï¼š

```yaml
pipeline.framework.sql-batch:
  parallel-query: true
  parallelism: 4
```

### Q4: å¦‚ä½•å¤„ç†é”™è¯¯ï¼Ÿ

**A:** ä½¿ç”¨Reactorçš„é”™è¯¯å¤„ç†ï¼š

```java
executor.execute(job)
    .doOnError(error -> log.error("ä»»åŠ¡å¤±è´¥", error))
    .retry(3)  // é‡è¯•3æ¬¡
    .subscribe();
```

## ğŸ“š æ›´å¤šèµ„æº

- [å®Œæ•´é‡æ„æŒ‡å—](REFACTORING_GUIDE.md)
- [SQLæ‰¹é‡ä»»åŠ¡ç¤ºä¾‹](SQL_BATCH_EXAMPLE.md)
- [é‡æ„æ€»ç»“](README_REFACTORING.md)
- [APIæ–‡æ¡£](https://docs.pipeline-framework.example.com)

## ğŸ†˜ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ

1. æŸ¥çœ‹æ–‡æ¡£ï¼š[docs/](docs/)
2. æŸ¥çœ‹ç¤ºä¾‹ï¼š[SQL_BATCH_EXAMPLE.md](SQL_BATCH_EXAMPLE.md)
3. æäº¤Issueï¼š[GitHub Issues](https://github.com/your-org/pipeline-framework/issues)
4. å‘é€é‚®ä»¶ï¼špipeline-framework-team@example.com

## ğŸ‰ å¼€å§‹ä½¿ç”¨

```bash
# 1. ç¼–è¯‘
mvn clean install

# 2. è¿è¡Œç¤ºä¾‹
cd pipeline-starter
mvn spring-boot:run

# 3. è®¿é—®
open http://localhost:8080/actuator/health
```

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€

å¦‚æœè§‰å¾—æœ‰ç”¨ï¼Œåˆ«å¿˜äº†ç»™é¡¹ç›®ä¸€ä¸ª â­ï¸
